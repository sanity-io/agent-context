---
name: optimize-agent-prompt
description: Optimize system prompts for agents using Sanity Agent Context. Load when improving agent responses, integrating dataset exploration results, or tuning how an agent queries and presents Sanity content. Covers prompt structure, dataset knowledge integration, and user-facing tone.
---

# Optimize Agent Prompt for Sanity Agent Context

Use this skill when improving the system prompt for an agent that connects to a Sanity Agent Context (MCP) server. This skill helps you incorporate dataset exploration results (`dataset-knowledge.md`) into your agent's prompt so it queries accurately and speaks naturally on behalf of the brand.

## When to Use This Skill

- You are improving a system prompt for an agent that uses Sanity Agent Context
- You have a `dataset-knowledge.md` file from running `@sanity/agent-context-explorer`
- Your agent is returning wrong answers, exposing internal details, or hallucinating
- You want your agent to avoid common data pitfalls (wrong field names, missing data, external dependencies)

## Prerequisites

1. **A working agent** — built using the `create-agent-with-sanity-context` skill or equivalent
2. **A `dataset-knowledge.md` file** — generated by running the Agent Context Explorer against your dataset
3. **Access to the agent's system prompt** — you need to be able to edit the prompt the agent receives

If you don't have a `dataset-knowledge.md` yet, install and run the explorer:

```bash
npm install -g @sanity/agent-context-explorer

agent-context-explorer \
  --mcp-url <your-agent-context-url> \
  --questions <your-questions.json> \
  --auth-token <your-token> \
  --anthropic-api-key <your-anthropic-key>
```

Always include `expected_answer` in your questions — the explorer uses it to guide exploration and validate results:

```json
{
  "questions": [
    {
      "question": "What sizes does the Trailblazer Hiking Boot come in?",
      "expected_answer": "US 7-13, including half sizes"
    },
    {
      "question": "Is the Ultralight Tent waterproof?",
      "expected_answer": "Yes, it has a 3000mm waterproof rating with taped seams"
    }
  ]
}
```

## Core Principle: Speak On Behalf Of, Not About

The agent represents the brand. It should talk like a knowledgeable team member, not like a database administrator. Users don't care about document types, query patterns, or data sources — they want answers.

**Bad** (talking about the dataset):

> "The pricing data is not available in this dataset. It is managed in the Commerce API external system. The product document type does not contain a price field."

**Good** (talking on behalf of the brand):

> "I don't have current pricing available. You can check pricing on our website or contact our sales team."

**Bad** (exposing internals):

> "I queried the product type and found the Trailblazer Boot in the name field. Based on the variant data, it appears to come in sizes 7-13."

**Good** (clean answer):

> "The Trailblazer Hiking Boot comes in US sizes 7-13, including half sizes."

The `dataset-knowledge.md` teaches the agent how to find answers. The user should only see the answers themselves.

## What Makes a Good Agent Context Prompt

A production agent prompt has six parts. Incorporate knowledge from `dataset-knowledge.md` into each:

### 1. Role Statement

Tell the agent who it is — as a representative of the brand, not as a data tool. Keep it to 2-3 sentences.

```
You are a helpful assistant for [Company]. You help customers with product
questions, setup guidance, and troubleshooting. Be friendly, direct, and concise.
```

### 2. Schema Reference

Pull from the "What This Dataset Contains" section of `dataset-knowledge.md`. Give the agent a compact reference so it knows where to look — but frame it as product knowledge, not database schema:

```
## What You Know About

| Topic | Where to Look | Key Fields |
|-------|--------------|------------|
| Products | product | name, productCategory, media |
| Product details | productVariant | name, sku, specs |
| Help & setup | supportArticle | title, body, tags |
```

Include "What is NOT in this dataset" — but phrase the boundary as what the agent can and can't help with:

```
## What You Can't Help With
- Pricing — direct customers to the website
- Order status or account issues — direct to customer support
- Real-time stock availability — direct to the website or a retail partner
```

### 3. Query Strategy by Question Type

Pull from "How to Query (by Question Category)" in `dataset-knowledge.md`. For each category, provide the approach and pitfalls inline:

```
## How to Answer Different Questions

### Product questions
Look up the product by name, then pull specs from its variants.
Use the `name` field, never `title` (it's empty). If asked about colors, check
media alt text — dedicated color fields are empty.

### Compatibility questions
Search support articles first. Don't infer compatibility from product specs alone.

### Comparisons
Always look up both products before answering. Pull the same fields from each
so the comparison is fair.
```

### 4. Critical Patterns

Pull from "Traps (Global Hazards)" in `dataset-knowledge.md`. These are internal rules the agent follows silently — the user never sees them:

```
## Internal Rules (never mention these to the user)
- Use `name` not `title` for product lookups — `title` is always empty
- Filter by `lang == "en-us"` to avoid duplicate results
- If semantic search returns low-confidence results, fall back to direct lookup
```

### 5. Fallback Strategy

Tell the agent how to handle gaps gracefully — without exposing the machinery:

```
## When You Don't Have an Answer
- If the information isn't available, say so simply: "I don't have that
  information available, but you can find it at [relevant resource]."
- Never guess or make up an answer
- Never mention databases, queries, document types, or data sources to the user
- If you're unsure, say what you DO know and offer to help with related questions
```

### 6. Tone and Format

End with output style rules:

```
## How to Respond
- Give direct answers first, then add detail if helpful
- Don't narrate your process ("Let me look that up...", "I found that...")
- Don't cite your sources ("According to the product database...")
- Use natural language, not technical jargon
- Keep answers concise — a few sentences for simple questions, short paragraphs
  for comparisons
```

## How to Integrate Knowledge from dataset-knowledge.md

When reading `dataset-knowledge.md` to build your prompt, follow these guidelines:

1. **Inline hazards with their query patterns.** Don't create a separate "hazards" section. Put each pitfall next to the question type it affects.

2. **Prioritize "What is NOT here" items.** These prevent the worst failure: the agent confidently making up answers for data that doesn't exist. Frame them as "what you can't help with" rather than "what's missing from the dataset."

3. **Use concrete field names, not generic advice.** Replace "use the correct field name" with "use `name` not `title`." The knowledge doc has real examples — use them.

4. **Keep the prompt under 2000 words.** Longer prompts dilute attention. Prioritize: (a) what the agent can't help with, (b) field naming traps, (c) query approaches, (d) everything else.

5. **Trust the confidence levels.** Items marked `[High]` in the knowledge doc are reliable. Items marked `[Low]` should be treated as provisional — don't build hard rules around them.

6. **Separate internal rules from user-facing tone.** The agent needs to know about document types and field names to query correctly. But it should never surface this to the user. Keep technical details in "internal rules" sections and keep the user-facing guidance focused on natural communication.

## What NOT to Do

- **Don't paste the entire `dataset-knowledge.md` into the system prompt.** It's too long and the agent will ignore most of it. Extract the relevant parts and structure them as described above.
- **Don't include GROQ syntax tutorials.** The Agent Context MCP server handles query execution. The agent needs to know _what_ to query, not _how_ GROQ works.
- **Don't add the skill content itself to the prompt.** This skill helps _you_ write the prompt. The agent should get the resulting prompt, not these instructions.
- **Don't remove existing prompt sections that work.** This skill is additive — integrate knowledge alongside your existing prompt, don't replace it wholesale.
- **Don't let the agent talk like a database.** Phrases like "the document type," "this field is null," "query returned no results," or "data is managed in [external system]" should never appear in user-facing output. Reframe everything as natural product knowledge.
- **Don't use the term "Context MCP" in customer-facing prompts.** The product name is "Agent Context." "Context MCP" is an internal name.
